<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: TDD | Ostia]]></title>
  <link href="http://ostia.be/blog/categories/tdd/atom.xml" rel="self"/>
  <link href="http://ostia.be/"/>
  <updated>2013-02-27T23:10:08+01:00</updated>
  <id>http://ostia.be/</id>
  <author>
    <name><![CDATA[Ben Verbeken]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Legacy code, an epyphany]]></title>
    <link href="http://ostia.be/blog/2013/01/29/legacy-code/"/>
    <updated>2013-01-29T08:14:00+01:00</updated>
    <id>http://ostia.be/blog/2013/01/29/legacy-code</id>
    <content type="html"><![CDATA[<p>Until recently, I used the term <em>legacy code</em> for bad, ancient code that had been written ten consultants ago, for code that has stopped evolving because it's too complicated and critical that nobody dares to take responsibility, for code that came from someone else, you get the idea. We've all seen that code and we all love to hate that consultant, don't we.</p>

<p>And then I learned about another definition of legacy code, one that Michael Feathers (<a href="https://twitter.com/mfeathers">@mfeathers</a>) introduced in his book, <a href="http://www.informit.com/store/working-effectively-with-legacy-code-9780131177055">Working Effectively with Legacy Code</a>:</p>

<p><blockquote><p>legacy code is code without tests.</p></blockquote></p>

<p>Nice, short and catchy, but until yesterday I didn't really understand this is indeed a very good definition of legacy code.</p>

<!-- more -->


<p>I'm working on a large scale web application, in a company with multiple teams, each of which is responsible for a single application.<br/>
One of the guys on my team, let's call him Alex, had been working on a restful web service api that would be called by one of those other teams. Couple of days work, the story card moved from TODO over DOING to DONE on our kanban board, story done.</p>

<p>Fast forward a couple of weeks. A guy from the other team, Bart, comes in and tells me there's something wrong with the webservice: in a specific case, our code wouldn't reply with a <em>bad request</em>, but an <em>ok</em>. A bug. No biggie, but a bug nevertheless. I go look in the code, to only find production code. Not a single test there.</p>

<p><em>(Before going on, an important note: I'm not blaming Alex. Nobody writes bugfree code. In Alex's defence, this web service api is a thin layer on top of the core application and thin layers should be trivial. So I understand why writing tests in this case seem like a waste of time.)</em></p>

<p>Back to the bug. I have a couple of options here.</p>

<ul>
<li>I could <strong>delegate</strong> the bug to Alex, so that it's not my problem anymore. However, Alex is part of the team today, but what if another bug bites when he's not anymore?</li>
<li>I could debug through the code, until I find the bug. <strong>Just fix it</strong> and be done with it. But how do I know I don't introduce a new bug? How do I make sure I fixed the bug?</li>
<li>Better, I could <strong>write a single test</strong> that reproduces this bug, and then fix it. However,  we'd still rely on the other team's testing to know whether our api is any good. Furthermore, it could be hard to write a single failing test; perhaps the code as it is now is not very testable, given that it had been written without tests in the first place.</li>
<li>I could treat our web service api like a nuclear reactor: build a concrete shield <strong>wall of solid integration tests</strong> around it, without touching the code. Then refactor, and then write the test that reproduces the bug. But that would be very time-consuming.</li>
</ul>


<p>All of these options above are flawed to some degree. Either they involve unprofessional behaviour, or I need to spend more time then I would like to solve the bug.</p>

<p>The point is that I have the exact same options of responding to this particular bug as I do for a bug in bad code that's been there for years. It doesn't matter when the code was written or whether the guy who wrote it is still on the team or not, untested code is a black box.  <br/>
And if the cure is the same, it must be the same disease, the rest is just politics and religion.</p>

<p>Hence: legacy code is untested code and untested code is legacy code, QED.</p>

<p><em>On a side note: Michael Feathers will be doing a keynote at the <a href="https://twitter.com/JoyOfCoding">@JoyOfCoding</a> conference in Rotterdam (The Netherlands) soon. I doubt I'll be able to make it there, my family's got a major release coming up. But do check it out, <a href="http://joyofcoding.org">the program</a> is well worth it!</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[play 2 JUnit runner]]></title>
    <link href="http://ostia.be/blog/2012/10/20/play-2-test-runner/"/>
    <updated>2012-10-20T17:38:00+02:00</updated>
    <id>http://ostia.be/blog/2012/10/20/play-2-test-runner</id>
    <content type="html"><![CDATA[<p>I like Play 2. It's simply the best thing that happened on the JVM since, well, Play 1 :)</p>

<p>One thing bothers me though: testing is still a bit of a PITA (at least in Java). Sure, Play 2 has webdriver support, you don't have to extend <code>UnitTest</code> and <code>FunctionalTest</code> anymore and you can unit-test templates. But, instead of extending base test classes I have to call a bunch of static utility methods on the <code>play.test.Helpers</code> class.</p>

<p>For example, to write a test that runs inside an application (i.e. has access to its environment), I have to write the following:</p>

<script src="https://gist.github.com/3917715.js?file=BeforeOrganisationTest.java"></script>


<p>In his excellent <a href="http://blog.matthieuguillermin.fr/2012/03/unit-testing-tricks-for-play-2-0-and-ebean/">blog post</a>, Matthieu Guillermin (<a href="https://twitter.com/MGuillermin">@mguillermin</a>) shows a solution for this problem (amongs others) by creating an abstract base class that contains the boilerplate code.
This works very well, but I prefer composition over inheritance, so I'm using a custom JUnit runner for this.</p>

<script src="https://gist.github.com/3917715.js?file=PlayJUnitRunner.java"></script>


<p>Then, you can use this runner in an <code>@runWith</code> annotation, and just write your test code without wrapping it in a <code>Runnable</code>, like so:</p>

<script src="https://gist.github.com/3917715.js?file=AfterOrganisationTest.java"></script>


<p>Until next time!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[To Test Or Not To Test]]></title>
    <link href="http://ostia.be/blog/2012/08/29/totestornottotest/"/>
    <updated>2012-08-29T23:04:00+02:00</updated>
    <id>http://ostia.be/blog/2012/08/29/totestornottotest</id>
    <content type="html"><![CDATA[<p>I recently decided to participate in a <a href="http://www.radrace.org/en/index.html">RAD race</a>, which will be held on 9 and 10 November. A RAD race is a competition in which teams (of two people in this case) build a real-life application in two days, using the language and tools of their choice. <!-- more -->   <br/>
'Rapid Application Development' is an old term whose meaning changed a couple of times over the course of history and even brings back memories of some IBM products *shivers*. But the fact that people still organise these events shows that we keep looking for better, cheaper, faster ways of building software. This  particular RAD race is being held for the 15th time, nuff said.</p>

<h2>The Problem</h2>

<p>On the technology side everything is clear. We'll be building the app using <a href="http://www.playframework.org">PlayFramework</a> - only the single best way to build java web apps -, Java, Twitter Bootstrap, JQuery. We'll be using Git for version management, and probably Eclipse on Windows. I'm still in negotiation with my teammate - let's call him Matti - about the latter two. (If you ask him, we're only negotiating about Git and perhaps a client-side mvc framework. In short: no question there ;-)).</p>

<p>But right in the middle of the excitement Matti and I felt when we decided to enter the competition, a question popped up: what about <strong>testing</strong>?   <br/>
What should we test? When should we be writing them? Should we be writing any tests at all?</p>

<p>For any real project, the answer would be simple: we'd be writing tests for everything, and we'd be writing them first.
But for the RAD race, things may be different.</p>

<h2>The funny thing about simulation games</h2>

<p>As a student, I regularily participated in stock exchange simulation games. That is, until I got annoyed enough by the fact that the winner was always the one who put all of his play money in one basket. Sure, for every winner, there were tens of people who used the same strategy and didn't win, but neither did the ones who did build a life-like diversified portfolio.</p>

<p>The point is that every simulation game rule system has its flaws, and that participants can exploit these flaws in order to win. In most stock exchange simulation games, the flaw is that there's no real money,  so in order to maximize profit, you take as much (fake) risk as you can.  <br/>
In a RAD race, the flaw is that your code won't be running in production for years to come. There won't be angry users asking for quick hacks on the phone, and no third or fourth generation junior developer who's made responsible for maintaining the damned thing.</p>

<h2>TDD vs Time</h2>

<p>Does this mean that my teammate and I won't be writing time-consuming tests during the RAD race? Hell no!</p>

<p>First, saying that TDD is time-consuming is like saying your bookkeeper is costing you money. If it is, you're doing it wrong. <br/>
TDD is about producing time, namely time you won't be spending looking for that annoying business blocking bug. Which will probably be during a weekend in your holiday or the one right before your code goes into production.  <br/>
And if your code doesn't go into production, the bug will definitely bite you during the demo you're giving to one of the RAD race judges.</p>

<p>Secondly, saying that writing tests is time-consuming implies a direct relationship between Lines Of Code and Time. Or that the productivity of a programmer can be measured in LOC, which is absurd, of course.</p>

<p>So we won't be writing legacy code (aka code without tests) from the start of the RAD race. We will, however, adapt ourselves to the situation, <em>in casu</em> a simulation game situation.  <br/>
We'll plan to TDD the business logic, especially if there's complex algorithms involved. And we'll have UI tests that cover at least every page in the app, but probably without checking every possible corner case.     <br/>
But I'm still negotiating on that with Matti.</p>
]]></content>
  </entry>
  
</feed>
